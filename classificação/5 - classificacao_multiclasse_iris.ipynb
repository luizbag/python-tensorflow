{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_x = StandardScaler()\n",
    "X = scaler_x.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot = OneHotEncoder(categorical_features = [0])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = onehot.fit_transform(y).toarray()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronios_entrada = X.shape[1]\n",
    "neuronios_entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronios_oculta = int(np.ceil((X.shape[1] + y.shape[1]) / 2))\n",
    "neuronios_oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronios_saida = y.shape[1]\n",
    "neuronios_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = {'oculta': tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_oculta, neuronios_saida]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {'oculta': tf.Variable(tf.random_normal([neuronios_oculta])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_saida]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xph = tf.placeholder('float', [None, neuronios_entrada])\n",
    "yph = tf.placeholder('float', [None, neuronios_saida])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, W, bias):\n",
    "    camada_oculta = tf.add(tf.matmul(x, W['oculta']), bias['oculta'])\n",
    "    camada_oculta_ativacao = tf.nn.relu(camada_oculta)\n",
    "    camada_saida = tf.add(tf.matmul(camada_oculta_ativacao, W['saida']), b['saida'])\n",
    "    return camada_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = mlp(xph, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = modelo, labels = yph))\n",
    "otimizador = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "batch_total = int(len(X_treinamento) / batch_size)\n",
    "batch_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batches = np.array_split(X_treinamento, batch_total)\n",
    "X_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batches[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoca in range(3000):\n",
    "        erro_medio = 0.0\n",
    "        batch_total = int(len(X_treinamento) / batch_size)\n",
    "        X_batches = np.array_split(X_treinamento, batch_total)\n",
    "        y_batches = np.array_split(y_treinamento, batch_total)\n",
    "        for i in range(batch_total):\n",
    "            X_batch, y_batch = X_batches[i], y_batches[i]\n",
    "            _, custo = sess.run([otimizador, erro], feed_dict = {xph: X_batch, yph: y_batch})\n",
    "            erro_medio += custo / batch_total\n",
    "        if epoca % 500 == 0:\n",
    "            print('Época: ' + str((epoca + 1)) + ' erro: ' + str(erro_medio))\n",
    "    W_final, b_final = sess.run([W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previsões\n",
    "previsoes_teste = mlp(xph, W_final, b_final)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    r1 = sess.run(previsoes_teste, feed_dict = {xph: X_teste})\n",
    "    r2 = sess.run(tf.nn.softmax(r1))\n",
    "    r3 = sess.run(tf.argmax(r2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste2 = np.argmax(y_teste, 1)\n",
    "y_teste2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "taxa_acerto = accuracy_score(y_teste2, r3)\n",
    "taxa_acerto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
